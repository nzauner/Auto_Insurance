{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Analysis\n",
    "\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "\n",
    "- Analyze auto insurance data.\n",
    "- Build a logistic regression model to predict crash probability for auto insurance customers.\n",
    "- Build a linear regression model to predict crash cost for auto insurance customers.\n",
    "- Use model results to develop crash percentage and assign customers to new risk profiles.\n",
    "- Determine cost of premiums based on risk profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    "\n",
    "The dataset for this project contains 6043 records of auto insurance data. Each record\n",
    "represents a customer at an auto insurance company. Using this data, we will be able to ascertain what\n",
    "influences the likelihood of a car crash. Then subsequently, we will be able to determine the cost to resolve a claim. The data in this project is the typical type of corporate data you would receive from a company in the insurance field-- a typical flat file from client records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "%run ../python_files/imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash</th>\n",
       "      <th>crash_cost</th>\n",
       "      <th>kidsdriv</th>\n",
       "      <th>age</th>\n",
       "      <th>homekids</th>\n",
       "      <th>yoj</th>\n",
       "      <th>income</th>\n",
       "      <th>parent1</th>\n",
       "      <th>home_val</th>\n",
       "      <th>mstatus</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>job</th>\n",
       "      <th>travtime</th>\n",
       "      <th>car_use</th>\n",
       "      <th>bluebook</th>\n",
       "      <th>tif</th>\n",
       "      <th>car_type</th>\n",
       "      <th>red_car</th>\n",
       "      <th>oldclaim</th>\n",
       "      <th>clm_freq</th>\n",
       "      <th>revoked</th>\n",
       "      <th>mvr_pts</th>\n",
       "      <th>car_age</th>\n",
       "      <th>urbanicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>67349.381620</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Professional</td>\n",
       "      <td>13.950586</td>\n",
       "      <td>Private</td>\n",
       "      <td>14230</td>\n",
       "      <td>11</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>4461</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>91449.254640</td>\n",
       "      <td>No</td>\n",
       "      <td>257251.6354</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>High School</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>21.943209</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>14940</td>\n",
       "      <td>1</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>16038.587100</td>\n",
       "      <td>No</td>\n",
       "      <td>124190.7529</td>\n",
       "      <td>Yes</td>\n",
       "      <td>F</td>\n",
       "      <td>High School</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Private</td>\n",
       "      <td>4010</td>\n",
       "      <td>4</td>\n",
       "      <td>SUV</td>\n",
       "      <td>no</td>\n",
       "      <td>38690</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2946.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>125301.242500</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>F</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>45.703013</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>17430</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports Car</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>62977.824160</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>F</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>33.639949</td>\n",
       "      <td>Private</td>\n",
       "      <td>11200</td>\n",
       "      <td>1</td>\n",
       "      <td>SUV</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6255.902602</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>High School</td>\n",
       "      <td>Student</td>\n",
       "      <td>40.664049</td>\n",
       "      <td>Private</td>\n",
       "      <td>5600</td>\n",
       "      <td>1</td>\n",
       "      <td>Pickup</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Highly Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>43111.840100</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>M</td>\n",
       "      <td>High School</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>50.996441</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>27330</td>\n",
       "      <td>10</td>\n",
       "      <td>Panel Truck</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Highly Rural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>164668.837000</td>\n",
       "      <td>No</td>\n",
       "      <td>386273.4090</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Manager</td>\n",
       "      <td>21.267951</td>\n",
       "      <td>Private</td>\n",
       "      <td>13270</td>\n",
       "      <td>15</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>43445.497870</td>\n",
       "      <td>No</td>\n",
       "      <td>149247.7801</td>\n",
       "      <td>Yes</td>\n",
       "      <td>F</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Home Maker</td>\n",
       "      <td>36.170517</td>\n",
       "      <td>Private</td>\n",
       "      <td>22550</td>\n",
       "      <td>6</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>53235.335970</td>\n",
       "      <td>No</td>\n",
       "      <td>197017.4730</td>\n",
       "      <td>Yes</td>\n",
       "      <td>F</td>\n",
       "      <td>High School</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>63.804264</td>\n",
       "      <td>Private</td>\n",
       "      <td>19400</td>\n",
       "      <td>6</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Rural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6044 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      crash  crash_cost  kidsdriv  age  homekids  yoj         income parent1  \\\n",
       "0         0         0.0         0   60         0   11   67349.381620      No   \n",
       "1         0         0.0         0   43         0   11   91449.254640      No   \n",
       "2         0         0.0         0   35         1   10   16038.587100      No   \n",
       "3         1      2946.0         0   34         1   12  125301.242500     Yes   \n",
       "4         1      2501.0         0   34         0   10   62977.824160      No   \n",
       "...     ...         ...       ...  ...       ...  ...            ...     ...   \n",
       "6039      0         0.0         0   41         0    7    6255.902602      No   \n",
       "6040      0         0.0         0   35         0   11   43111.840100      No   \n",
       "6041      0         0.0         1   45         2    9  164668.837000      No   \n",
       "6042      0         0.0         0   50         0    7   43445.497870      No   \n",
       "6043      0         0.0         0   52         0   11   53235.335970      No   \n",
       "\n",
       "         home_val mstatus sex    education           job   travtime  \\\n",
       "0          0.0000      No   M          PhD  Professional  13.950586   \n",
       "1     257251.6354      No   M  High School   Blue Collar  21.943209   \n",
       "2     124190.7529     Yes   F  High School      Clerical   5.000000   \n",
       "3          0.0000      No   F    Bachelors   Blue Collar  45.703013   \n",
       "4          0.0000      No   F    Bachelors      Clerical  33.639949   \n",
       "...           ...     ...  ..          ...           ...        ...   \n",
       "6039       0.0000      No   M  High School       Student  40.664049   \n",
       "6040       0.0000      No   M  High School   Blue Collar  50.996441   \n",
       "6041  386273.4090     Yes   M          PhD       Manager  21.267951   \n",
       "6042  149247.7801     Yes   F    Bachelors    Home Maker  36.170517   \n",
       "6043  197017.4730     Yes   F  High School      Clerical  63.804264   \n",
       "\n",
       "         car_use  bluebook  tif     car_type red_car  oldclaim  clm_freq  \\\n",
       "0        Private     14230   11      Minivan     yes      4461         2   \n",
       "1     Commercial     14940    1      Minivan     yes         0         0   \n",
       "2        Private      4010    4          SUV      no     38690         2   \n",
       "3     Commercial     17430    1   Sports Car      no         0         0   \n",
       "4        Private     11200    1          SUV      no         0         0   \n",
       "...          ...       ...  ...          ...     ...       ...       ...   \n",
       "6039     Private      5600    1       Pickup      no         0         0   \n",
       "6040  Commercial     27330   10  Panel Truck     yes         0         0   \n",
       "6041     Private     13270   15      Minivan      no         0         0   \n",
       "6042     Private     22550    6      Minivan      no         0         0   \n",
       "6043     Private     19400    6      Minivan      no         0         0   \n",
       "\n",
       "     revoked  mvr_pts  car_age           urbanicity  \n",
       "0         No        3       18  Highly Urban/ Urban  \n",
       "1         No        0        1  Highly Urban/ Urban  \n",
       "2         No        3       10  Highly Urban/ Urban  \n",
       "3         No        0        7  Highly Urban/ Urban  \n",
       "4         No        0        1  Highly Urban/ Urban  \n",
       "...      ...      ...      ...                  ...  \n",
       "6039      No        0        7         Highly Rural  \n",
       "6040      No        0        8         Highly Rural  \n",
       "6041      No        2       17  Highly Urban/ Urban  \n",
       "6042      No        0       11  Highly Urban/ Urban  \n",
       "6043      No        0        9         Highly Rural  \n",
       "\n",
       "[6044 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import auto insurance data\n",
    "auto_df = pd.read_csv('../data/auto_insurance_data.csv')\n",
    "\n",
    "# change column names to lower-case\n",
    "auto_df.columns = [i.lower() for i in auto_df.columns]\n",
    "\n",
    "# quick overview of the dataset\n",
    "auto_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a quick overview of the dataset, we see that we are working with 6044 total observations and 25 different variables. The response variable we will be using is Crash, which indicates whether a car was in a crash or not. The remaining 24 variables will be used as explanatory variables. We also notice a good mix of continuous and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick review of the variables in the dataset\n",
    "auto_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For modeling purposes, we know that we will have to convert all categorical variables to dummy variables. As we can see above, there are 10 categorical variables that will need to go through this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quick review of the characteristics of our current continuous variables in the dataset\n",
    "auto_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice above that there is a large range between some of our observations. However, it is not appropriate to dismiss these as outliers, as we do not want to skew or create bias within our dataset. Also, above we cannot view the descriptions of our 10 categorical variables until we convert them to continous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of NaN values in the dataset\n",
    "auto_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we see above that our dataset does not contain any missing values, so we will not need to worry about imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy values for the categorical variables\n",
    "\n",
    "auto_df['mstatus'] = auto_df['mstatus'].map({'Yes': 1, 'No': 0})\n",
    "auto_df['sex'] = auto_df['sex'].map({'M': 1, 'F': 0})\n",
    "auto_df['parent1'] = auto_df['parent1'].map({'Yes': 1, 'No': 0})\n",
    "auto_df['red_car'] = auto_df['red_car'].map({'yes': 1, 'no': 0})\n",
    "auto_df['revoked'] = auto_df['revoked'].map({'Yes': 1, 'No': 0})\n",
    "auto_df['urbanicity'] = auto_df['urbanicity'].map({'Highly Urban/ Urban': 1, 'Highly Rural': 0})\n",
    "auto_df['education'] = auto_df['education'].map({'<High School': 0, 'High School': 0, 'Bachelors': 1, 'Masters': 1, 'PhD': 1})\n",
    "auto_df['job'] = auto_df['job'].map({'Student': 1, 'Blue Collar': 0, 'Clerical': 0, 'Doctor': 0, 'Home Maker': 0, 'Lawyer': 0, 'Manager': 0, 'Professional': 0})\n",
    "auto_df['car_use'] = auto_df['car_use'].map({'Commercial': 1, 'Private': 0})\n",
    "auto_df['car_type'] = auto_df['car_type'].map({'Sports Car': 1, 'SUV': 1, 'Minivan': 1, 'Pickup': 0, 'Van': 0, 'Panel Truck': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformations for non-normalized variables. Drop the original variable from the dataset.\n",
    "\n",
    "def log_col(df, col):\n",
    "    '''Convert column to log values and\n",
    "    drop the original column\n",
    "    '''\n",
    "    df[f'{col}_log'] = np.log(df[col])\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "log_col(auto_df, 'tif')\n",
    "log_col(auto_df, 'bluebook')\n",
    "log_col(auto_df, 'travtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# quick review of the characteristics of all variables in the dataset, \n",
    "# including the new dummy variables and log-transformed variables\n",
    "auto_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Train and Test Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split auto_insurance_df into train and test datasets for our logistic and linear regression models\n",
    "\n",
    "#'features' will be used in both models\n",
    "features = auto_df.drop(['crash', 'crash_cost'], axis = 1)\n",
    "\n",
    "#train and test datasets for logistic regression model\n",
    "crash = auto_df['crash']\n",
    "x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(features, crash, test_size = 0.2, random_state = 10)\n",
    "\n",
    "#train and test datasets for simple linear regression model\n",
    "crash_cost = auto_df['crash_cost']\n",
    "x_train_lin, x_test_lin, y_train_lin, y_test_lin = train_test_split(features, crash_cost, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations for logistic regression model\n",
    "x_train_log.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation Heatmap for logistic regression model\n",
    "\n",
    "mask = np.zeros_like(x_train_log.corr())\n",
    "triangle_indices = np.triu_indices_from(mask)\n",
    "mask[triangle_indices] = True\n",
    "\n",
    "plt.figure(figsize=(35,30))\n",
    "ax = sns.heatmap(x_train_log.corr(method='pearson'), cmap=\"coolwarm\", mask=mask, annot=True, annot_kws={\"size\": 18}, square=True, linewidths=4)\n",
    "sns.set_style('white')\n",
    "plt.xticks(fontsize=14, rotation=45)\n",
    "plt.yticks(fontsize=14, rotation=0)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "#plt.ylabel(ylabel=' ', labelpad=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations for simple linear regression model\n",
    "x_train_lin.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap for simple linear regression model\n",
    "\n",
    "mask = np.zeros_like(x_train_lin.corr())\n",
    "triangle_indices = np.triu_indices_from(mask)\n",
    "mask[triangle_indices] = True\n",
    "\n",
    "plt.figure(figsize=(35,30))\n",
    "ax = sns.heatmap(x_train_lin.corr(method='pearson'), cmap=\"coolwarm\", mask=mask, annot=True, annot_kws={\"size\": 18}, square=True, linewidths=4)\n",
    "sns.set_style('white')\n",
    "plt.xticks(fontsize=14, rotation=45)\n",
    "plt.yticks(fontsize=14, rotation=0)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "#plt.ylabel(ylabel=' ', labelpad=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "rfecv_log = RFECV(estimator=logreg_model, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "rfecv_log.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance_log = list(zip(features, rfecv_log.support_))\n",
    "new_features_log = []\n",
    "for key,value in enumerate(feature_importance_log):\n",
    "    if(value[1]) == True:\n",
    "        new_features_log.append(value[0])\n",
    "        \n",
    "print(new_features_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination for Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_model = LinearRegression()\n",
    "rfecv_lin = RFECV(estimator=linreg_model, step=1, scoring='r2')\n",
    "rfecv_lin.fit(x_train_lin, y_train_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance_lin = list(zip(features, rfecv_lin.support_))\n",
    "new_features_lin = []\n",
    "for key,value in enumerate(feature_importance_lin):\n",
    "    if(value[1]) == True:\n",
    "        new_features_lin.append(value[0])\n",
    "        \n",
    "print(new_features_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Train and Test Datasets after Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final train and test datasets for logistic regression model\n",
    "x_train_log = x_train_log[new_features_log]\n",
    "x_test_log = x_test_log[new_features_log]\n",
    "\n",
    "#final train and test datasets for simple linear regression model\n",
    "x_train_lin = x_train_lin[new_features_lin]\n",
    "x_test_lin = x_test_lin[new_features_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_log.shape)\n",
    "print(x_test_log.shape)\n",
    "print(x_train_lin.shape)\n",
    "print(x_test_lin.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
